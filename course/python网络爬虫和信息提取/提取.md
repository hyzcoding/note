# 提取

## BeautifulSoup

- 简介

  > 解析html 、xml 文件
  >
  > 是解析、遍历、维护“标签树”的功能库

- 安装

  ```bash
  pip install beautifulsoup4
  ```

- 测试

  ```python
  import requests
  from bs4 import BeautifulSoup
  r = requests.get("http://www.baidu.com")
  demo = r.text
  soup = BeautifulSoup(demo,"html.parser")
  soup = BeautifulSoutp(open('aaa.html'),'html.parser')
  print(soup.prettify())
  ```

- 基本元素

  | 基本元素        | 说明                                                        |
  | --------------- | ----------------------------------------------------------- |
  | Tag             | 标签，基本的信息组织单元                                    |
  | Name            | 标签的名称`<p>`的名称是p，格式：`<tag>.name`                |
  | Attributes      | 标签的属性，字典形式组织，格式：`<tag>.attrs`               |
  | NavigableString | 标签内非属性字符串`<>..</>`中的字符串，格式：`<tag>.string` |
  | Commnet         | 标签内字符串的注释部分                                      |

  

- 引用

  ```python
  import bs4
  from bs4 import BeautifulSoup
  ```

- 解析器

  | 解析器           | 使用方法                          | 条件                   |
  | ---------------- | --------------------------------- | ---------------------- |
  | bs4的HTML解析器  | `BeautifulSoup(mk,'html.parser')` | 安装bs4库              |
  | lxml的HTML解析器 | `BeautifulSoup(mk,'lxml')`        | `pip install lxml`     |
  | lxml的XML解析器  | `BeautifulSoup(mk,'xml')`         | `pip install lxml`     |
  | html5lib的解析器 | `BeautifulSoup(mk,'html5lib')`    | `pip install html5lib` |

- 方法

  ```python
  from bs4 import BeautifulSoup
  soup = BeautifulSoup(demo,'html.parser')
  soup.title # 获取<title>标签的内容 
  soup.a # 返回第一个
  soup.a.name
  soup.a.parent.name # p
  soup.a.parent.parent.name # body 字符串类型
  tag = soup.a
  tag.attrs
  tag.attrs['class']
  type(tag.attrs)
  tag.string # 可以跨越多个标签格式
  # 去除注释部分
  ```

- 遍历

  - 下行遍历

    | 属性           | 说明                                                         |
    | -------------- | ------------------------------------------------------------ |
    | `.contents`    | 子节点的列表，将`<tag>`所有节点存入列表                      |
    | `.childrens`   | 子节点的迭代类型，与.content类似，用于循环遍历子节点 只能存在于for中 |
    | `.descendants` | 子孙节点的迭代类型，包含所有子孙节点，用于循环遍历           |

    ```python
    soup.head # 获取head标签
    contents = soup.head.contents # 儿子节点列表
    len(soup.body.contents)
    contents[1]
    ```

  - 上行遍历

    | 属性       | 说明               |
    | ---------- | ------------------ |
    | `.parent`  | 节点的父亲标签     |
    | `.parents` | 节点的先辈标签列表 |

    ```python
    a = soup.a
    a.parent
    a.parents
    soup.html.parent # html 父亲是本身
    soup.parent # 先辈不存在
    if parent NotNull
    ```

    

  - 平行遍历

    > 同一个父亲节点下

    | 属性                 | 说明                                        |
    | -------------------- | ------------------------------------------- |
    | `.next_sibling`      | 返回下一个平行节点标签                      |
    | `.previous_sibling`  | 上一个平行节点标签                          |
    | `.next_siblings`     | 后续所有平行节点标签 只能存在 for in 循环中 |
    | `.previous_siblings` | 前续所有平行节点标签 只能存在 for in 循环中 |

    ```python
    soup.a.next_sibling # 可能存在 NavigableString类型
    soup.a.next_sibling.next_sibling # 无则返回空信息
    ```

## 信息组织与提取方法

- 信息标记

  - 功能
    - 标记后的信息可以形成信息组织结构，增加信息维度
    - 标记后的信息可用于通信、存储或展示
    - 标记的结构与信息一样具有重要价值
    - 标记后的信息更利于程序理解与运用

  > HTML的信息标记
  >
  > - 通过预定义的<></> 标识不同的信息

  - 种类

    | 种类 | 描述           | 适用场景                                   |
    | ---- | -------------- | ------------------------------------------ |
    | xml  | *扩展标记语言* | Internet上的信息交互与传递                 |
    | json | 有类型的键值对 | 移动应用云端和节点的信息通信，无法体现注释 |
    | yaml | 无类型的键值对 | 各类系统的配置文件，有注释易读             |

- 提取方法

  1. 完整解析信息的标记形式，再提取关键信息。

     需要标记解析器 例如：bs4库的标签树遍历

     信息解析准确，但过程繁琐，解析速度慢

  2. 无视标记形式，直接搜索关键信息。

     对信息的文本查找函数即可。

     提取简单，提取结果的准确性和信息结果直接相关

  3. 融合方法

     需要解析器和查找函数

  例： 提取url连接

  ```python
  from bs4 import BeautifulSoup
  soup = BeautifulSoup(demo,"html.parser")
  for link in soup.find_all('a'):
      print(link.get('href'))
  ```

## 基于bs4库的HTML内容查找方法

- `.find_all(name,attrs,recursive,string,**kwargs)`

| 字段      | 说明                           |
| --------- | ------------------------------ |
| name      | 对标签字段的检索字符串         |
| attrs     | 标签属性检索                   |
| recursive | 是否对子孙全部检索，默认为True |
| string    | 对字符串区域进行检索`<>...</>` |

```
<tag>() = <tag>.find_all()
soup() = soup.find_all()
```

```python 
import requests
import re
from bs4 import BeautifulSoup
r = requests.get("http://www.baidu.com")
demo = r.text
soup = BeautifulSoup(demo,"html.parser")
soup.find_all(['a','b']) # 查询a标签和b标签
soup.find_all(True) # 查询所有标签
soup.find_all(re.complile('b')) # 查询所有含有b的标签 
soup.find_all('p','course') # 属性包含某个值
soup.find_all('div',id='mydiv')
soup.find_all(id=re.complile('b'))
soup.find_all('p',recursive)
soup.find_all(string=re.complile('含有xx'))
```



| 方法                     | 说明               | 方法                     | 说明     |
| ------------------------ | ------------------ | ------------------------ | -------- |
| .find()                  | 返回一个字符串结果 | .find_parents()          | 列表类型 |
| .find_parent()           | 字符串             | .find_next_siblings()    | 列表类型 |
| .find_next_sibling()     | 字符串             | .find_previous_siblins() | 列表类型 |
| .find_previous_sibling() | 字符串             |                          |          |



## 实例

> 静态信息，而不是js生成的动态信息

```python
import requests
from bs4 import BeautifulSoup
import bs4

'''
	最好大学排名
'''
# 获取网页
def get_html_text(url):
    try:
        r = requests.get(url,timeout=30)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text
    except Exception as e:
        print(e)
   		return ""
# 提取信息
def fill_univ_list(ulist,html):
    soup = BeautifulSoup(html,"html.parser")
    for tr in soup.find('tbody').children:
        if isinstance(tr, bs4.element.Tag):
            tds = tr('td')
        	ulist.append([tds[0].string,tds[1].string,tds[2].string])

# 合理数据结构 二维数据结构
def print_univ_list(ulist,num):
    # 使用第3个填充学校名称
    tplt = "{0:^10}\t{1:{3}^10}\t{2:^10}"
    print(tplt.format("排名","学校名称","总分",chr(12288)))
    for i in range(num):
        u = ulist[i]
    	print("{:^10}\t{:^6}\t{:^10}".format(u[0],u[1],u[2]))
    
def main():
    uinfo = []
    url = "排名url"
    html = get_html_text(url)
    fill_univ_list(uinfo, html)
    print_univ_list(uinfo,10)
    
main()
```

